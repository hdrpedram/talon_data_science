{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Source:** https://archive.ics.uci.edu/dataset/492/metro+interstate+traffic+volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Load the dataset \n",
    "file_path = 'data/Metro_Interstate_Traffic_Volume.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()\n",
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how \"Holday\" Column values show up as 'NaN' where there are actually \"None\" when opened in Excel? We need to instruct Pandas to avoid reading those as NaN or Null as this will become an issue later in the processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and treat 'None' as a regular string\n",
    "data = pd.read_csv(file_path, keep_default_na=False)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But What if there are actual \"Null/NaN\" values? This approach will ignore those as well which is not desired. We will have to use a trwo step approach for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset normally\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Replace NaN values in 'holiday' column with the string 'None'\n",
    "# data['holiday'].fillna('None', inplace=True)  # Old Pandas Method\n",
    "data.fillna({'holiday': 'None'}, inplace=True)  # New Pandas Method\n",
    "# Check the changes\n",
    "print(data['holiday'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduce Noise and Issues to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Let's randomly introduce missing values into 'temp', 'rain_1h', and 'traffic_volume'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to randomly insert NaN values\n",
    "def insert_missing(df, column, percentage=0.05):\n",
    "    num_missing = int(len(df) * percentage)\n",
    "    missing_indices = random.sample(range(len(df)), num_missing)\n",
    "    for i in missing_indices:\n",
    "        df.at[i, column] = np.nan\n",
    "\n",
    "# Insert missing values\n",
    "insert_missing(data, 'temp')\n",
    "insert_missing(data, 'rain_1h')\n",
    "insert_missing(data, 'traffic_volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Now, We’ll add outliers to the temp and traffic_volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add outliers\n",
    "def add_outliers(df, column, percentage=0.01, scale=3):\n",
    "    num_outliers = int(len(df) * percentage)\n",
    "    outlier_indices = random.sample(range(len(df)), num_outliers)\n",
    "    for i in outlier_indices:\n",
    "        outlier_value = df[column].mean() + scale * df[column].std() * random.choice([-1, 1])\n",
    "        df.at[i, column] = outlier_value\n",
    "\n",
    "# Add outliers to temp and traffic_volume\n",
    "add_outliers(data, 'temp')\n",
    "add_outliers(data, 'traffic_volume')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Next, we introduce Categorical Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce errors in categorical data\n",
    "def introduce_errors(df, column, error_rate=0.01):\n",
    "    categories = df[column].unique()\n",
    "    num_errors = int(len(df) * error_rate)\n",
    "    error_indices = random.sample(range(len(df)), num_errors)\n",
    "    for i in error_indices:\n",
    "        df.at[i, column] = random.choice(categories) + random.choice(['x', ' ', '#', '!'])\n",
    "\n",
    "introduce_errors(data, 'weather_main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Finally, We’ll add duplicate records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce duplicates\n",
    "def add_duplicates(df, num_duplicates=10):\n",
    "    duplicates = df.sample(n=num_duplicates, replace=False)\n",
    "    df = pd.concat([df, duplicates], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "data = add_duplicates(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 20 rows of the new dataset\n",
    "data.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the modified dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/modified_Metro_traffic_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
